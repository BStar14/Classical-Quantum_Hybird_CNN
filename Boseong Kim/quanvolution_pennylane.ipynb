{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quanvolution-pennylane.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "752579dbebe7f4dfe7c1aa72eac13e23fc88be2cc1ea7ab14e1f8d69b2d97d12"
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit ('3.8')",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "orig_nbformat": 4
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BStar14/Classical-Quantum_Hybird_CNN/blob/main/Boseong%20Kim/quanvolution_pennylane.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWGbvrK5Ej0E"
      },
      "source": [
        "## 1. Module Import, Select Device, and Download MNIST Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leBa4O5SE2Qd"
      },
      "source": [
        "### 1-1. Setup & Module Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBH5ggGT_R45"
      },
      "source": [
        "!pip install pennylane pennylane-ionq qiskit[visualization]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5fdX88pX2op"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "from pennylane.templates import RandomLayers\n",
        "from pennylane_ionq import ops\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import qiskit\n",
        "from qiskit import transpile, assemble\n",
        "from qiskit.visualization import *\n",
        "from qiskit.circuit.random import random_circuit\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Function\n",
        "from torchvision import datasets, transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1qX39BwFZue"
      },
      "source": [
        "### 1-2. Select Device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q60i4j6gX9Dw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb518bbc-370d-4b2a-cb48-6a033f0a2558"
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "if use_cuda:\n",
        "    DEVICE = torch.device('cuda')\n",
        "    print('cuda index:', torch.cuda.current_device())\n",
        "    print('GPU:', torch.cuda.get_device_name())\n",
        "else:\n",
        "    DEVICE = torch.device('cpu')\n",
        "\n",
        "print('Using PyTorch version:', torch.__version__, ' Device:', DEVICE)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using PyTorch version: 1.9.0+cu102  Device: cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiVGLmmJFcfn"
      },
      "source": [
        "### 1-3. Setting of the main hyper-parameters of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kISDupKdX2or"
      },
      "source": [
        "BATCH_SIZE = 10\n",
        "n_epochs = 30   # Number of optimization epochs\n",
        "n_layers = 1    # Number of random layers\n",
        "n_train = 50    # Size of the train dataset\n",
        "n_test = 30     # Size of the test dataset\n",
        "learning_rate = 5e-3\n",
        "\n",
        "SAVE_PATH = \"quanvolution_pqc/\" # Data saving folder\n",
        "PREPROCESS = True           # If False, skip quantum processing and load data from SAVE_PATH\n",
        "seed = 47\n",
        "np.random.seed(seed)        # Seed for NumPy random number generator\n",
        "torch.manual_seed(seed)     # Seed for TensorFlow random number generator\n",
        "\n",
        "os.environ['IONQ_API_KEY']='1LCa7Dvzz5P35g6B3gwoxzFO04n7gWYH'   # IonQ Token\n",
        "#dev = qml.device(\"ionq.qpu\", wires=9)\n",
        "dev = qml.device(\"default.qubit\", wires=9)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8MHcj-rI7j4"
      },
      "source": [
        "### 1-4. Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98toQ5ujX2os"
      },
      "source": [
        "from torch.utils.data import SubsetRandomSampler\n",
        "train_dataset = datasets.MNIST(root = \"./mnist_data\",\n",
        "                               train = True,\n",
        "                               download = True,\n",
        "                               transform = transforms.Compose([\n",
        "                                               transforms.Resize(size=14),\n",
        "                                               transforms.ToTensor()]))\n",
        "\n",
        "test_dataset = datasets.MNIST(root = \"./mnist_data\",\n",
        "                              train = False,\n",
        "                              transform = transforms.Compose([\n",
        "                                              transforms.Resize(size=14),\n",
        "                                              transforms.ToTensor()]))\n",
        "\n",
        "# train_dataset = Subset(train_dataset,range(n_train))\n",
        "# test_dataset = Subset(test_dataset,range(n_test))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(range(n_train))\n",
        "test_sampler = SubsetRandomSampler(range(n_test))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                                           batch_size = BATCH_SIZE,\n",
        "                                           shuffle = False,\n",
        "                                           sampler = train_sampler)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
        "                                          batch_size = BATCH_SIZE,\n",
        "                                          shuffle = False,\n",
        "                                          sampler = test_sampler)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQE9eNpYJIyJ",
        "outputId": "5b91980c-5919-44c3-ca73-638a922aca3c"
      },
      "source": [
        "for (X_train, y_train) in train_loader:\n",
        "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
        "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
        "    break"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train: torch.Size([10, 1, 14, 14]) type: torch.FloatTensor\n",
            "y_train: torch.Size([10]) type: torch.LongTensor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "id": "e2XHBWaGJPU2",
        "outputId": "a0986d2e-68b1-4427-fe9c-4edded90a6f1"
      },
      "source": [
        "pltsize = 1\n",
        "plt.figure(figsize=(10 * pltsize, pltsize))\n",
        "for i in range(10):\n",
        "    plt.subplot(1, 10, i + 1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(X_train[i, :, :, :].numpy().reshape(14, 14), cmap = \"gray_r\")\n",
        "    plt.title('Class: ' + str(y_train[i].item()))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x72 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raQ2L0JcMJOk"
      },
      "source": [
        "## 2. Construct Quantum Circuit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReIxz4NjMNHZ"
      },
      "source": [
        "### 2-1. Create a 'Quantum Class' with Qiskit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EUd926PX2os"
      },
      "source": [
        "# Random circuit parameters\n",
        "\n",
        "@qml.qnode(dev, interface='torch')\n",
        "def pqc(data,params,circuit_type):\n",
        "    n_qubits = 9\n",
        "    for j in range(n_qubits):\n",
        "        qml.RY(np.pi * data[j], wires=j)\n",
        "                      \n",
        "    if circuit_type == 2:     # len(params) == 18\n",
        "        # PQC\n",
        "        for i in range(n_qubits):\n",
        "            qml.RX(params[i], wires=i)\n",
        "        for i in range(n_qubits):\n",
        "            qml.RX(params[i+n_qubits], wires=i)\n",
        "        for i in range(n_qubits-1,0,-1):\n",
        "            qml.CNOT(wires=[i,i-1])    \n",
        "    elif circuit_type == 3:   # len(params) == 26\n",
        "        # PQC\n",
        "        for i in range(n_qubits):\n",
        "            qml.RX(params[i], wires=i)\n",
        "        for i in range(n_qubits):\n",
        "            qml.RX(params[i+n_qubits], wires=i)\n",
        "        for k,i in enumerate(range(n_qubits-1,0,-1)):\n",
        "            qml.CRZ(params[k+2*n_qubits], wires=[i,i-1])\n",
        "    elif circuit_type == 9:   # len(params) == 9\n",
        "        # PQC\n",
        "        for i in range(n_qubits):\n",
        "            qml.Hadamard(wires=i)\n",
        "        for i in range(n_qubits-1,0,-1):\n",
        "            qml.CZ(wires=[i,i-1])\n",
        "        for i in range(n_qubits):\n",
        "            qml.RX(params[i],wires=i)\n",
        "    elif circuit_type == 10:  # len(params) == 18\n",
        "        for i in range(n_qubits):\n",
        "            qml.RY(params[i],wires=i)\n",
        "        for i in range(n_qubits-1,0,-1):\n",
        "            qml.CZ(wires=[i,i-1])\n",
        "            qml.CZ(wires=[0,n_qubits-1])\n",
        "        for i in range(n_qubits):\n",
        "            qml.RY(params[i+n_qubits],wires=i)\n",
        "    elif circuit_type == 'random':\n",
        "        # Random quantum circuit\n",
        "        rand_params = np.random.uniform(high=2 * np.pi, size=(n_layers, n_qubits))\n",
        "        RandomLayers(rand_params, wires=list(range(4)))\n",
        "    else:\n",
        "        print(\"Invalid circuit_type\")\n",
        "        raise NotImplementedError\n",
        "    # Measurement producing 9 classical output values\n",
        "    return qml.expval(qml.PauliZ(0))"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvCObUDBX2ot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0380aa6e-1a35-4827-d854-606e5e038675"
      },
      "source": [
        "print(pqc(torch.tensor([1,0,2,1,2,3,1,2,0]),torch.tensor([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]), 'random'))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.5221, dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpBrzK8YuET4"
      },
      "source": [
        "class QuanvNet(torch.nn.Module):\n",
        "    def __init__(self,qc=True,opt=True,circuit_type=9):\n",
        "        super().__init__()\n",
        "        self.qc = qc\n",
        "        self.opt = opt\n",
        "        self.n_qubits = 9\n",
        "        self.filters = 1\n",
        "        self.conv_opt = torch.nn.Conv2d(in_channels=self.filters,out_channels=self.filters,kernel_size=3)\n",
        "        self.conv1 = torch.nn.Conv2d(in_channels=self.filters,out_channels=8,kernel_size=3,padding='same')\n",
        "        self.pre_pool = torch.nn.AvgPool2d(2)\n",
        "        self.pool = torch.nn.MaxPool2d(2)\n",
        "        self.conv2 = torch.nn.Conv2d(in_channels=8,out_channels=8,kernel_size=3)\n",
        "        self.fc1 = torch.nn.Linear(32,16)\n",
        "        self.fc2 = torch.nn.Linear(16,10)\n",
        "        self.dropout = torch.nn.Dropout(0.4)\n",
        "        if circuit_type == 2:\n",
        "          self.num_q_params = 2*self.n_qubits\n",
        "        elif circuit_type == 3:\n",
        "          self.num_q_params = 3*self.n_qubits - 1\n",
        "        elif circuit_type == 9:\n",
        "          self.num_q_params = self.n_qubits\n",
        "        elif circuit_type == 10:\n",
        "          self.num_q_params = 2*self.n_qubits\n",
        "        self.q_params = torch.nn.Parameter(2*np.pi*torch.rand(self.filters,self.num_q_params))\n",
        "        self.q_params.requires_grad = True\n",
        "        if self.qc:\n",
        "          self.circuit_type = circuit_type\n",
        "        else:\n",
        "          self.circuit_type = 0\n",
        "\n",
        "    def forward(self, inputs, check_plot=0):\n",
        "        if self.qc == True:\n",
        "            out = torch.zeros((BATCH_SIZE,self.filters,12,12))\n",
        "            for bat, image in enumerate(inputs):\n",
        "                for j in range(1, 13, 1):\n",
        "                    for k in range(1, 13, 1):\n",
        "                        for i in range(self.filters):\n",
        "                            window = image[0, j-1:j+2, k-1:k+2].squeeze()\n",
        "                            window_flatten = window.reshape(self.n_qubits)\n",
        "                            q_results = pqc(\n",
        "                                window_flatten,\n",
        "                                self.q_params[i],\n",
        "                                circuit_type=self.circuit_type\n",
        "                            )\n",
        "                            if use_cuda:\n",
        "                              out[bat,i,j - 1, k - 1] = F.relu(q_results.cuda())\n",
        "                            else:\n",
        "                              out[bat,i,j - 1, k - 1] = F.relu(q_results)\n",
        "\n",
        "            if check_plot == 1:\n",
        "              pltsize = 1\n",
        "              plt.figure(figsize=(BATCH_SIZE * pltsize, n_channels * pltsize))\n",
        "              for i in range(BATCH_SIZE):\n",
        "                for j in range(0, n_channels, 3):\n",
        "                  plt.subplot((n_channels+2)/3, BATCH_SIZE, i + j*BATCH_SIZE/3 + 1)\n",
        "                  plt.axis('off')\n",
        "                  plt.imshow(out[i, j, :, :].reshape(12, 12), cmap = \"gray_r\")\n",
        "\n",
        "        else:\n",
        "          if use_cuda:\n",
        "            out = torch.zeros((BATCH_SIZE,self.filters,14,14)).cuda()\n",
        "          else:\n",
        "            out = torch.zeros((BATCH_SIZE,self.filters,14,14))\n",
        "          out = inputs\n",
        "        # print(out.size())\n",
        "        if self.opt==True:\n",
        "          out = F.relu(self.conv_opt(inputs))\n",
        "        # print(\"out\", out.type)\n",
        "        x = self.pool(F.relu(self.conv1(out)))\n",
        "\n",
        "        # print(\"x\", x.type)\n",
        "        # print(x.size())\n",
        "        # print(x.size())\n",
        "        if check_plot == 1:\n",
        "          conv_image = x.cpu().detach().numpy()\n",
        "          pltsize = 1\n",
        "          plt.figure(figsize=(BATCH_SIZE * pltsize, n_channels * pltsize))\n",
        "          for i in range(BATCH_SIZE):\n",
        "            for j in range(0, n_channels, 3):\n",
        "              plt.subplot((n_channels+2)/3, BATCH_SIZE, i + j*BATCH_SIZE/3 + 1)\n",
        "              plt.axis('off')\n",
        "              plt.imshow(conv_image[i, j, :, :].reshape(6, 6), cmap = \"gray_r\")\n",
        "        \n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x,1)\n",
        "        # print(x.size())\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.softmax(self.fc2(x))\n",
        "        if use_cuda:\n",
        "          return x.cuda()\n",
        "        else:\n",
        "          return x"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6UzG0EiX2ou",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7240ffc-2f12-41af-e5c7-7b95bb1c9ddf"
      },
      "source": [
        "from torchsummary import summary\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "model = QuanvNet(qc=True,opt=False)\n",
        "if use_cuda:\n",
        "    model.cuda()\n",
        "opt = optim.Adam(model.parameters(),lr=learning_rate)\n",
        "summary(model,(1,14,14))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 12, 12]              80\n",
            "         MaxPool2d-2              [-1, 8, 6, 6]               0\n",
            "            Conv2d-3              [-1, 8, 4, 4]             584\n",
            "         MaxPool2d-4              [-1, 8, 2, 2]               0\n",
            "            Linear-5                   [-1, 16]             528\n",
            "           Dropout-6                   [-1, 16]               0\n",
            "            Linear-7                   [-1, 10]             170\n",
            "================================================================\n",
            "Total params: 1,362\n",
            "Trainable params: 1,362\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.01\n",
            "Params size (MB): 0.01\n",
            "Estimated Total Size (MB): 0.02\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:89: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2oZQZNkX2ov",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0daa688e-ef4f-49c1-a37d-bc10709d9fda"
      },
      "source": [
        "for p in model.parameters():\n",
        "    print(p.shape)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 9])\n",
            "torch.Size([1, 1, 3, 3])\n",
            "torch.Size([1])\n",
            "torch.Size([8, 1, 3, 3])\n",
            "torch.Size([8])\n",
            "torch.Size([8, 8, 3, 3])\n",
            "torch.Size([8])\n",
            "torch.Size([16, 32])\n",
            "torch.Size([16])\n",
            "torch.Size([10, 16])\n",
            "torch.Size([10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NSXfcDc0WHZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e9c6b6f-87e1-4d3c-e07b-6f3f7dc7bbee"
      },
      "source": [
        "losses = []\n",
        "accs = []\n",
        "check_plot=0\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  \n",
        "  train_loss = 0\n",
        "  acc = 0\n",
        "\n",
        "  for (x_train, y_train) in train_loader:\n",
        "    \n",
        "    # print(y_train)\n",
        "\n",
        "    if check_plot == 1:\n",
        "      pltsize = 1\n",
        "      plt.figure(figsize=(BATCH_SIZE * pltsize, pltsize))\n",
        "      for i in range(BATCH_SIZE):\n",
        "        plt.subplot(1, BATCH_SIZE, i + 1)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(x_train[i, :, :, :].numpy().reshape(14, 14), cmap = \"gray_r\")\n",
        "        plt.title('Class: ' + str(y_train[i].item()))\n",
        "\n",
        "    opt.zero_grad()\n",
        "    outputs = model(x_train.cuda() if use_cuda else x_train, check_plot=check_plot)\n",
        "    _, preds = torch.max(outputs,1)\n",
        "    acc += (preds==(y_train.cuda() if use_cuda else y_train)).sum().item()\n",
        "    loss = criterion(outputs,(y_train.cuda() if use_cuda else y_train))\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    train_loss += loss\n",
        "    del loss\n",
        "  acc /= n_train\n",
        "  train_loss /= (n_train/BATCH_SIZE)\n",
        "  losses.append(train_loss.item())\n",
        "  accs.append(acc)\n",
        "  print(f'epoch: {epoch+1}, acc: {acc}, loss: {train_loss}')\n",
        "  del acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:89: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 1, acc: 0.12, loss: 2.3022027015686035\n",
            "epoch: 2, acc: 0.16, loss: 2.299938678741455\n",
            "epoch: 3, acc: 0.16, loss: 2.2986063957214355\n",
            "epoch: 4, acc: 0.12, loss: 2.2970006465911865\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhALf9PmX2ov"
      },
      "source": [
        "from matplotlib.pyplot import plot\n",
        "x = np.arange(0,1000,10)\n",
        "plot(x,losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WqQOezuX2ow"
      },
      "source": [
        "x = np.arange(0,1000,10)\n",
        "plot(x,accs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2_nXF-wSC_I"
      },
      "source": [
        "file = pd.DataFrame(data={'train_loss': losses,\n",
        "                          'train_acc': accs})\n",
        "file.to_pickle(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jE7WBpF_qnA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}