{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quanvolution-pennylane.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "752579dbebe7f4dfe7c1aa72eac13e23fc88be2cc1ea7ab14e1f8d69b2d97d12"
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit ('3.8')",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "orig_nbformat": 4
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BStar14/Classical-Quantum_Hybird_CNN/blob/main/Boseong%20Kim/quanvolution_pennylane.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWGbvrK5Ej0E"
      },
      "source": [
        "## 1. Module Import, Select Device, and Download MNIST Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leBa4O5SE2Qd"
      },
      "source": [
        "### 1-1. Setup & Module Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBH5ggGT_R45"
      },
      "source": [
        "!pip install pennylane pennylane-ionq qiskit[visualization]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5fdX88pX2op"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "from pennylane.templates import RandomLayers\n",
        "from pennylane_ionq import ops\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import qiskit\n",
        "from qiskit import transpile, assemble\n",
        "from qiskit.visualization import *\n",
        "from qiskit.circuit.random import random_circuit\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Function\n",
        "from torchvision import datasets, transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1qX39BwFZue"
      },
      "source": [
        "### 1-2. Select Device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q60i4j6gX9Dw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb518bbc-370d-4b2a-cb48-6a033f0a2558"
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "if use_cuda:\n",
        "    DEVICE = torch.device('cuda')\n",
        "    print('cuda index:', torch.cuda.current_device())\n",
        "    print('GPU:', torch.cuda.get_device_name())\n",
        "else:\n",
        "    DEVICE = torch.device('cpu')\n",
        "\n",
        "print('Using PyTorch version:', torch.__version__, ' Device:', DEVICE)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using PyTorch version: 1.9.0+cu102  Device: cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiVGLmmJFcfn"
      },
      "source": [
        "### 1-3. Setting of the main hyper-parameters of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kISDupKdX2or"
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "n_epochs = 30   # Number of optimization epochs\n",
        "n_layers = 1    # Number of random layers\n",
        "n_train = 128   # Size of the train dataset\n",
        "n_test = 32     # Size of the test dataset\n",
        "learning_rate = 5e-3\n",
        "\n",
        "SAVE_PATH = \"quanvolution_pqc/\" # Data saving folder\n",
        "PREPROCESS = True           # If False, skip quantum processing and load data from SAVE_PATH\n",
        "seed = 47\n",
        "np.random.seed(seed)        # Seed for NumPy random number generator\n",
        "torch.manual_seed(seed)     # Seed for TensorFlow random number generator\n",
        "\n",
        "os.environ['IONQ_API_KEY']='1LCa7Dvzz5P35g6B3gwoxzFO04n7gWYH'   # IonQ Token\n",
        "#dev = qml.device(\"ionq.qpu\", wires=9)\n",
        "dev = qml.device(\"default.qubit\", wires=9)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8MHcj-rI7j4"
      },
      "source": [
        "### 1-4. Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98toQ5ujX2os"
      },
      "source": [
        "from torch.utils.data import SubsetRandomSampler\n",
        "train_dataset = datasets.MNIST(root = \"./mnist_data\",\n",
        "                               train = True,\n",
        "                               download = True,\n",
        "                               transform = transforms.Compose([\n",
        "                                               transforms.Resize(size=14),\n",
        "                                               transforms.ToTensor()]))\n",
        "\n",
        "test_dataset = datasets.MNIST(root = \"./mnist_data\",\n",
        "                              train = False,\n",
        "                              transform = transforms.Compose([\n",
        "                                              transforms.Resize(size=14),\n",
        "                                              transforms.ToTensor()]))\n",
        "\n",
        "# train_dataset = Subset(train_dataset,range(n_train))\n",
        "# test_dataset = Subset(test_dataset,range(n_test))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(range(n_train))\n",
        "test_sampler = SubsetRandomSampler(range(n_test))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                                           batch_size = BATCH_SIZE,\n",
        "                                           shuffle = False,\n",
        "                                           sampler = train_sampler)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
        "                                          batch_size = BATCH_SIZE,\n",
        "                                          shuffle = False,\n",
        "                                          sampler = test_sampler)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQE9eNpYJIyJ",
        "outputId": "e6839fea-e2e6-435d-c40e-2e6d9549bedb"
      },
      "source": [
        "for (X_train, y_train) in train_loader:\n",
        "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
        "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
        "    break"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train: torch.Size([16, 1, 14, 14]) type: torch.FloatTensor\n",
            "y_train: torch.Size([16]) type: torch.LongTensor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "id": "e2XHBWaGJPU2",
        "outputId": "ad44c9e3-e16f-4766-8d0c-0096a8b89082"
      },
      "source": [
        "pltsize = 1\n",
        "plt.figure(figsize=(10 * pltsize, pltsize))\n",
        "for i in range(10):\n",
        "    plt.subplot(1, 10, i + 1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(X_train[i, :, :, :].numpy().reshape(14, 14), cmap = \"gray_r\")\n",
        "    plt.title('Class: ' + str(y_train[i].item()))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x72 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raQ2L0JcMJOk"
      },
      "source": [
        "## 2. Construct Quantum Circuit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReIxz4NjMNHZ"
      },
      "source": [
        "### 2-1. Create a 'Quantum Class' with Qiskit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EUd926PX2os"
      },
      "source": [
        "# Random circuit parameters\n",
        "\n",
        "@qml.qnode(dev, interface='torch')\n",
        "def pqc(data,params,circuit_type):\n",
        "    n_qubits = 9\n",
        "    for j in range(n_qubits):\n",
        "        qml.RY(np.pi * data[j], wires=j)\n",
        "                      \n",
        "    if circuit_type == 2:     # len(params) == 18\n",
        "        # PQC\n",
        "        for i in range(n_qubits):\n",
        "            qml.RX(params[i], wires=i)\n",
        "        for i in range(n_qubits):\n",
        "            qml.RX(params[i+n_qubits], wires=i)\n",
        "        for i in range(n_qubits-1,0,-1):\n",
        "            qml.CNOT(wires=[i,i-1])    \n",
        "    elif circuit_type == 3:   # len(params) == 26\n",
        "        # PQC\n",
        "        for i in range(n_qubits):\n",
        "            qml.RX(params[i], wires=i)\n",
        "        for i in range(n_qubits):\n",
        "            qml.RX(params[i+n_qubits], wires=i)\n",
        "        for k,i in enumerate(range(n_qubits-1,0,-1)):\n",
        "            qml.CRZ(params[k+2*n_qubits], wires=[i,i-1])\n",
        "    elif circuit_type == 9:   # len(params) == 9\n",
        "        # PQC\n",
        "        for i in range(n_qubits):\n",
        "            qml.Hadamard(wires=i)\n",
        "        for i in range(n_qubits-1,0,-1):\n",
        "            qml.CZ(wires=[i,i-1])\n",
        "        for i in range(n_qubits):\n",
        "            qml.RX(params[i],wires=i)\n",
        "    elif circuit_type == 10:  # len(params) == 18\n",
        "        for i in range(n_qubits):\n",
        "            qml.RY(params[i],wires=i)\n",
        "        for i in range(n_qubits-1,0,-1):\n",
        "            qml.CZ(wires=[i,i-1])\n",
        "            qml.CZ(wires=[0,n_qubits-1])\n",
        "        for i in range(n_qubits):\n",
        "            qml.RY(params[i+n_qubits],wires=i)\n",
        "    elif circuit_type == 'random':\n",
        "        # Random quantum circuit\n",
        "        rand_params = np.random.uniform(high=2 * np.pi, size=(n_layers, n_qubits))\n",
        "        RandomLayers(rand_params, wires=list(range(4)))\n",
        "    else:\n",
        "        print(\"Invalid circuit_type\")\n",
        "        raise NotImplementedError\n",
        "    # Measurement producing 9 classical output values\n",
        "    return qml.expval(qml.PauliZ(0))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvCObUDBX2ot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f745c2f-4574-4b52-896d-8e8bd4a60cd8"
      },
      "source": [
        "print(pqc(torch.tensor([1,0,2,1,2,3,1,2,0]),torch.tensor([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]), 'random'))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.5221, dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpBrzK8YuET4"
      },
      "source": [
        "class QuanvNet(torch.nn.Module):\n",
        "    def __init__(self,qc=True,opt=True,circuit_type=9):\n",
        "        super().__init__()\n",
        "        self.qc = qc\n",
        "        self.opt = opt\n",
        "        self.n_qubits = 9\n",
        "        self.filters = 1\n",
        "        self.conv_opt = torch.nn.Conv2d(in_channels=self.filters,out_channels=self.filters,kernel_size=3)\n",
        "        self.conv1 = torch.nn.Conv2d(in_channels=self.filters,out_channels=8,kernel_size=3,padding='same')\n",
        "        self.pre_pool = torch.nn.AvgPool2d(2)\n",
        "        self.pool = torch.nn.MaxPool2d(2)\n",
        "        self.conv2 = torch.nn.Conv2d(in_channels=8,out_channels=8,kernel_size=3)\n",
        "        self.fc1 = torch.nn.Linear(32,16)\n",
        "        self.fc2 = torch.nn.Linear(16,10)\n",
        "        self.dropout = torch.nn.Dropout(0.4)\n",
        "        if circuit_type == 2:\n",
        "          self.num_q_params = 2*self.n_qubits\n",
        "        elif circuit_type == 3:\n",
        "          self.num_q_params = 3*self.n_qubits - 1\n",
        "        elif circuit_type == 9:\n",
        "          self.num_q_params = self.n_qubits\n",
        "        elif circuit_type == 10:\n",
        "          self.num_q_params = 2*self.n_qubits\n",
        "        self.q_params = torch.nn.Parameter(2*np.pi*torch.rand(self.filters,self.num_q_params))\n",
        "        self.q_params.requires_grad = True\n",
        "        if self.qc:\n",
        "          self.circuit_type = circuit_type\n",
        "        else:\n",
        "          self.circuit_type = 0\n",
        "\n",
        "    def forward(self, inputs, check_plot=0):\n",
        "        if self.qc == True:\n",
        "            out = torch.zeros((BATCH_SIZE,self.filters,12,12))\n",
        "            for bat, image in enumerate(inputs):\n",
        "                for j in range(1, 13, 1):\n",
        "                    for k in range(1, 13, 1):\n",
        "                        for i in range(self.filters):\n",
        "                            window = image[0, j-1:j+2, k-1:k+2].squeeze()\n",
        "                            window_flatten = window.reshape(self.n_qubits)\n",
        "                            q_results = pqc(\n",
        "                                window_flatten,\n",
        "                                self.q_params[i],\n",
        "                                circuit_type=self.circuit_type\n",
        "                            )\n",
        "                            if use_cuda:\n",
        "                              out[bat,i,j - 1, k - 1] = F.relu(q_results.cuda())\n",
        "                            else:\n",
        "                              out[bat,i,j - 1, k - 1] = F.relu(q_results)\n",
        "\n",
        "            if check_plot == 1:\n",
        "              pltsize = 1\n",
        "              plt.figure(figsize=(BATCH_SIZE * pltsize, n_channels * pltsize))\n",
        "              for i in range(BATCH_SIZE):\n",
        "                for j in range(0, n_channels, 3):\n",
        "                  plt.subplot((n_channels+2)/3, BATCH_SIZE, i + j*BATCH_SIZE/3 + 1)\n",
        "                  plt.axis('off')\n",
        "                  plt.imshow(out[i, j, :, :].reshape(12, 12), cmap = \"gray_r\")\n",
        "\n",
        "        else:\n",
        "          if use_cuda:\n",
        "            out = torch.zeros((BATCH_SIZE,self.filters,14,14)).cuda()\n",
        "          else:\n",
        "            out = torch.zeros((BATCH_SIZE,self.filters,14,14))\n",
        "          out = inputs\n",
        "        # print(out.size())\n",
        "        if self.opt==True:\n",
        "          out = F.relu(self.conv_opt(inputs))\n",
        "        # print(\"out\", out.type)\n",
        "        x = self.pool(F.relu(self.conv1(out)))\n",
        "\n",
        "        # print(\"x\", x.type)\n",
        "        # print(x.size())\n",
        "        # print(x.size())\n",
        "        if check_plot == 1:\n",
        "          conv_image = x.cpu().detach().numpy()\n",
        "          pltsize = 1\n",
        "          plt.figure(figsize=(BATCH_SIZE * pltsize, n_channels * pltsize))\n",
        "          for i in range(BATCH_SIZE):\n",
        "            for j in range(0, n_channels, 3):\n",
        "              plt.subplot((n_channels+2)/3, BATCH_SIZE, i + j*BATCH_SIZE/3 + 1)\n",
        "              plt.axis('off')\n",
        "              plt.imshow(conv_image[i, j, :, :].reshape(6, 6), cmap = \"gray_r\")\n",
        "        \n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x,1)\n",
        "        # print(x.size())\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.softmax(self.fc2(x))\n",
        "        if use_cuda:\n",
        "          return x.cuda()\n",
        "        else:\n",
        "          return x"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6UzG0EiX2ou",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "199c4b22-6ae1-4f81-80da-7cbcba875df7"
      },
      "source": [
        "from torchsummary import summary\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "model = QuanvNet(qc=True,opt=False)\n",
        "if use_cuda:\n",
        "    model.cuda()\n",
        "opt = optim.Adam(model.parameters(),lr=learning_rate)\n",
        "summary(model,(1,14,14))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 12, 12]              80\n",
            "         MaxPool2d-2              [-1, 8, 6, 6]               0\n",
            "            Conv2d-3              [-1, 8, 4, 4]             584\n",
            "         MaxPool2d-4              [-1, 8, 2, 2]               0\n",
            "            Linear-5                   [-1, 16]             528\n",
            "           Dropout-6                   [-1, 16]               0\n",
            "            Linear-7                   [-1, 10]             170\n",
            "================================================================\n",
            "Total params: 1,362\n",
            "Trainable params: 1,362\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.01\n",
            "Params size (MB): 0.01\n",
            "Estimated Total Size (MB): 0.02\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:89: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2oZQZNkX2ov",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b838f8d9-8c2e-41fb-aa67-fd2b37bab9a8"
      },
      "source": [
        "for p in model.parameters():\n",
        "    print(p.shape)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 9])\n",
            "torch.Size([1, 1, 3, 3])\n",
            "torch.Size([1])\n",
            "torch.Size([8, 1, 3, 3])\n",
            "torch.Size([8])\n",
            "torch.Size([8, 8, 3, 3])\n",
            "torch.Size([8])\n",
            "torch.Size([16, 32])\n",
            "torch.Size([16])\n",
            "torch.Size([10, 16])\n",
            "torch.Size([10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NSXfcDc0WHZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "outputId": "0632a6f6-9147-4912-9b03-328cbda60c21"
      },
      "source": [
        "losses = []\n",
        "accs = []\n",
        "check_plot=0\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  \n",
        "  train_loss = 0\n",
        "  acc = 0\n",
        "\n",
        "  for (x_train, y_train) in train_loader:\n",
        "    \n",
        "    # print(y_train)\n",
        "\n",
        "    if check_plot == 1:\n",
        "      pltsize = 1\n",
        "      plt.figure(figsize=(BATCH_SIZE * pltsize, pltsize))\n",
        "      for i in range(BATCH_SIZE):\n",
        "        plt.subplot(1, BATCH_SIZE, i + 1)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(x_train[i, :, :, :].numpy().reshape(14, 14), cmap = \"gray_r\")\n",
        "        plt.title('Class: ' + str(y_train[i].item()))\n",
        "\n",
        "    opt.zero_grad()\n",
        "    outputs = model(x_train.cuda() if use_cuda else x_train, check_plot=check_plot)\n",
        "    _, preds = torch.max(outputs,1)\n",
        "    acc += (preds==(y_train.cuda() if use_cuda else y_train)).sum().item()\n",
        "    loss = criterion(outputs,(y_train.cuda() if use_cuda else y_train))\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    train_loss += loss\n",
        "    del loss\n",
        "  acc /= n_train\n",
        "  train_loss /= (n_train/BATCH_SIZE)\n",
        "  losses.append(train_loss.item())\n",
        "  accs.append(acc)\n",
        "  print(f'epoch: {epoch+1}, acc: {acc}, loss: {train_loss}')\n",
        "  del acc"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:89: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 1, acc: 0.078125, loss: 2.3021862506866455\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-51999225a5c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;31m# _forward_cls is defined by derived class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pennylane/interfaces/torch.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(ctx, dy)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;34m\"\"\"Implements the backwards pass QNode vector-Jacobian product\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mvjp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjacobian\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0mvjp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvjp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvjp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pennylane/interfaces/torch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx_, parent_ctx, *input_)\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0mctx_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0mctx_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                 \u001b[0mjacobian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_evaluate_grad_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"jacobian\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mjacobian\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pennylane/interfaces/torch.py\u001b[0m in \u001b[0;36m_evaluate_grad_matrix\u001b[0;34m(grad_matrix_fn)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_params_unwrapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             grad_matrix = getattr(tape, grad_matrix_fn)(\n\u001b[0;32m--> 122\u001b[0;31m                 \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjacobian_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             )\n\u001b[1;32m    124\u001b[0m             \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pennylane/tape/qubit_param_shift.py\u001b[0m in \u001b[0;36mjacobian\u001b[0;34m(self, device, params, **options)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_append_evA_tape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evA_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparameter_shift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pennylane/tape/jacobian_tape.py\u001b[0m in \u001b[0;36mjacobian\u001b[0;34m(self, device, params, **options)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         \u001b[0;31m# execute all tapes at once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_tapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;31m# post-process the results with the appropriate function to fill jacobian columns with gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pennylane/_qubit_device.py\u001b[0m in \u001b[0;36mbatch_execute\u001b[0;34m(self, circuits)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pennylane/_qubit_device.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, circuit, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;31m# apply all circuit operations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiagonalizing_gates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;31m# generate computational basis samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pennylane/devices/default_qubit.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, operations, rotations, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_basis_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwires\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_operation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;31m# store the pre-rotated state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pennylane/devices/default_qubit.py\u001b[0m in \u001b[0;36m_apply_operation\u001b[0;34m(self, state, operation)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwires\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;31m# Einsum is faster for small gates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_unitary_einsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwires\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_unitary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwires\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pennylane/devices/default_qubit.py\u001b[0m in \u001b[0;36m_apply_unitary_einsum\u001b[0;34m(self, state, mat, wires)\u001b[0m\n\u001b[1;32m    645\u001b[0m             \u001b[0;32mlambda\u001b[0m \u001b[0mold_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_pair\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mold_string\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maffected_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m             \u001b[0mstate_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m         )\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhALf9PmX2ov"
      },
      "source": [
        "from matplotlib.pyplot import plot\n",
        "x = np.arange(0,1000,10)\n",
        "plot(x,losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WqQOezuX2ow"
      },
      "source": [
        "x = np.arange(0,1000,10)\n",
        "plot(x,accs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2_nXF-wSC_I"
      },
      "source": [
        "file = pd.DataFrame(data={'train_loss': losses,\n",
        "                          'train_acc': accs})\n",
        "file.to_pickle(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jE7WBpF_qnA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}