{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BStar14/Classical-Quantum_Hybird_CNN/blob/main/Boseong%20Kim/04_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOPI7p0ENVTH",
        "outputId": "f4f67318-cfd4-46f4-aed0-5c213d852153"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2uLSpfnNpDV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbedec31-d14a-4d7e-9d1b-f0da3b2550c0"
      },
      "source": [
        "cd/content/gdrive/MyDrive/Colab Notebooks/QHK2021/04_test"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/Colab Notebooks/QHK2021/04_test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKxNWKXWPBpj"
      },
      "source": [
        "!pip install pennylane --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3rDW9vwPIcu"
      },
      "source": [
        "!pip install qiskit ipywidgets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqc_rrHrmxD8"
      },
      "source": [
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "from pennylane.templates import RandomLayers\n",
        "import matplotlib.pyplot as plt\n",
        "from qiskit import *\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import SubsetRandomSampler\n",
        "\n",
        "import numpy.random as random\n",
        "import pandas as pd"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtM-9Y_ns6G8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1544039-98a5-47e8-90dd-8cf80922425e"
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "print(use_cuda)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qATAHWS0nvYL"
      },
      "source": [
        "n_epochs = 30     # Number of optimization epochs\n",
        "n_channels = 1    # Number of channels\n",
        "n_train = 128     # Size of the train dataset\n",
        "n_test = 32       # Size of the test dataset\n",
        "BATCH_SIZE = 16   # Size of batch\n",
        "\n",
        "SAVE_PATH = \"quanvolution_pqc/\"   # Data saving folder\n",
        "PREPROCESS = True                 # If False, skip quantum processing and load data from SAVE_PATH\n",
        "random.seed(0)                    # Seed for NumPy random number generator\n",
        "\n",
        "n_poly = 5                  # Order of polynomials\n",
        "n_kernel = 3**2             # Size of kernel\n",
        "\n",
        "rand_params = random.default_rng()\n",
        "rand_params = 1 - rand_params.standard_normal(size=(n_channels, n_poly, n_kernel))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K43NKx1P_L8C"
      },
      "source": [
        "train_dataset = datasets.MNIST(root = \"./\",\n",
        "                               train = True,\n",
        "                               download = True,\n",
        "                               transform = transforms.ToTensor())\n",
        "\n",
        "test_dataset = datasets.MNIST(root = \"./\",\n",
        "                              train = False,\n",
        "                              download = False,\n",
        "                              transform = transforms.ToTensor())\n",
        "\n",
        "train_sampler = SubsetRandomSampler(range(n_train))\n",
        "test_sampler = SubsetRandomSampler(range(n_test))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                                           batch_size = BATCH_SIZE,\n",
        "                                           shuffle = False,\n",
        "                                           sampler = train_sampler)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
        "                                          batch_size = BATCH_SIZE,\n",
        "                                          shuffle = False,\n",
        "                                          sampler = test_sampler)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8mq8VyMUa5A"
      },
      "source": [
        "token1 = '2b740fada862fb6d9683487f84455ff8fccb2caaa3988e4f406d321ef67ce0644eb679211a1b6a377ec5ee9b3839d34434255304ab535a9ed11ce60703f07446'\n",
        "token2 = '08952555d263c29c9b015855d49bcbf0e7a3cb1354b5520743285bb48d19f0db420522be05c80dd1fb19179c42d798b238ae7b944568bb6e7e7284d9bfeb0209'\n",
        "\n",
        "# from qiskit import IBMQ\n",
        "# IBMQ.save_account(token2)\n",
        "# provider = IBMQ.enable_account(token1)\n",
        "dev = qml.device(\"default.qubit\", wires=9)\n",
        "# dev = qml.device('qiskit.ibmq', wires=9, backend='ibmq_qasm_simulator',provider=provider)\n",
        "# IBMQ.get_provider(hub='ibm-q', group='open', project='main')\n",
        "# dev = qml.device('qiskit.ibmq', wires=9, backend='ibmq_qasm_simulator',\n",
        "                #  ibmqx_token=token1, hub='ibm-q', group='open', project='main')\n",
        "# print(dev.capabilities()['backend'])\n",
        "# import pennylane as qml\n",
        "# from pennylane_ionq import ops\n",
        "\n",
        "# dev = qml.device(\"ionq.qpu\", wires=9)\n",
        "\n",
        "# Random circuit parameters\n",
        "\n",
        "@qml.qnode(dev, interface='torch')\n",
        "def pqc(data,params):\n",
        "    # Encoding of 9 classical input values\n",
        "    # len(params) = 2 * 9\n",
        "    # print(\"data: \",data)\n",
        "    # print(\"params: \",params)\n",
        "    n_qubits = 9\n",
        "    for j in range(n_qubits):\n",
        "        qml.RY(np.pi * data[j], wires=j)\n",
        "    \n",
        "    # rand_params = np.random.uniform(high=2 * np.pi, size=(n_channels, 9))\n",
        "    # print(\"rand\", rand_params)\n",
        "    # PQC\n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(params[i], wires=i)\n",
        "    for i in range(n_qubits-1):\n",
        "        qml.CNOT(wires=[i,i+1])    \n",
        "    qml.CNOT(wires=[n_qubits-1,0])\n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(params[i+n_qubits], wires=i)\n",
        "    # Measurement producing 9 classical output values\n",
        "    return qml.expval(qml.PauliZ(0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8dfw_HFUetM",
        "outputId": "cbc426b0-fed6-4f1a-e9f4-12965e937ef7"
      },
      "source": [
        "print(pqc([1,0,2,1,2,3,1,2,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.5919, dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrxtmz60Uhmf"
      },
      "source": [
        "class QuanvNet(torch.nn.Module):\n",
        "    def __init__(self, qc=True, opt=True):\n",
        "        super().__init__()\n",
        "        self.qc = qc\n",
        "        self.opt = opt\n",
        "        self.n_qubits = 9\n",
        "        self.filters = 1\n",
        "        self.conv_opt = torch.nn.Conv2d(in_channels=self.filters,out_channels=self.filters,kernel_size=3)\n",
        "        self.conv1 = torch.nn.Conv2d(in_channels=self.filters,out_channels=8,kernel_size=3,padding='same')\n",
        "        self.pre_pool = torch.nn.AvgPool2d(2)\n",
        "        self.pool = torch.nn.MaxPool2d(2)\n",
        "        self.conv2 = torch.nn.Conv2d(in_channels=8,out_channels=8,kernel_size=3)\n",
        "        self.fc1 = torch.nn.Linear(32,16)\n",
        "        self.fc2 = torch.nn.Linear(16,10)\n",
        "        self.dropout = torch.nn.Dropout(0.4)\n",
        "        self.q_params = torch.nn.Parameter(2*np.pi*torch.rand(12,12,self.filters,2*self.n_qubits))\n",
        "        self.q_params.requires_grad = True\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        if self.qc == True:\n",
        "          out = torch.zeros((BATCH_SIZE,self.filters,12,12))\n",
        "          for bat, image in enumerate(inputs):\n",
        "              for j in range(1, 13, 1):\n",
        "                  for k in range(1, 13, 1):\n",
        "                      for i in range(self.filters):\n",
        "                          q_results = pqc(\n",
        "                          [\n",
        "                              image[0, j - 1, k - 1].item(),\n",
        "                              image[0, j - 1, k].item(),\n",
        "                              image[0, j - 1, k + 1].item(),\n",
        "                              image[0, j, k - 1].item(),\n",
        "                              image[0, j, k].item(),\n",
        "                              image[0, j, k + 1].item(),\n",
        "                              image[0, j + 1, k - 1].item(),\n",
        "                              image[0, j + 1, k].item(),\n",
        "                              image[0, j + 1, k + 1].item()\n",
        "                          ],\n",
        "                              self.q_params[j-1,k-1,i]\n",
        "                          )\n",
        "                          out[bat,i,j - 1, k - 1] = q_results\n",
        "        else:\n",
        "          out = torch.zeros((BATCH_SIZE,self.filters,14,14))\n",
        "          out = inputs\n",
        "        print(out.size())\n",
        "        if use_cuda:\n",
        "          out = out.cuda()\n",
        "        if self.opt==True:\n",
        "          out = self.conv_opt(inputs)\n",
        "        x = self.pool(F.relu(self.conv1(out)))\n",
        "        print(x.size())\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x,1)\n",
        "        print(x.size())\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.softmax(self.fc2(x))\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHK7QHXqVHw9"
      },
      "source": [
        "## Random Polynomial Definition\n",
        "def rand_poly(x_kernel):\n",
        "\n",
        "  # result_array = []\n",
        "  # for i in range(n_channels):\n",
        "    i = 0                     # i is originally channel index\n",
        "    result = .0\n",
        "    for j in range(n_poly):\n",
        "      for k, x in enumerate(x_kernel):\n",
        "        result = result + rand_params[i, j, k] * (x ** j)\n",
        "    # result_array.append(result)\n",
        "\n",
        "    # originally returns result_array\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJpNi3EeVqFV"
      },
      "source": [
        "class NLNet(torch.nn.Module):\n",
        "    def __init__(self, nl=True, opt=False):\n",
        "        super().__init__()\n",
        "        self.nl = nl\n",
        "        self.opt = opt\n",
        "        self.filters = 1\n",
        "        self.conv_opt = torch.nn.Conv2d(in_channels=self.filters,out_channels=self.filters,kernel_size=3)\n",
        "        self.conv1 = torch.nn.Conv2d(in_channels=self.filters,out_channels=8,kernel_size=3,padding='same')\n",
        "        self.pre_pool = torch.nn.AvgPool2d(2)\n",
        "        self.pool = torch.nn.MaxPool2d(2)\n",
        "        self.conv2 = torch.nn.Conv2d(in_channels=8,out_channels=8,kernel_size=3)\n",
        "        self.fc1 = torch.nn.Linear(32,16)\n",
        "        self.fc2 = torch.nn.Linear(16,10)\n",
        "        self.dropout = torch.nn.Dropout(0.4)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        if self.nl == True:\n",
        "          out = torch.zeros((BATCH_SIZE,self.filters,12,12))\n",
        "          for bat, image in enumerate(inputs):\n",
        "              for j in range(1, 13, 1):\n",
        "                  for k in range(1, 13, 1):\n",
        "                      for i in range(self.filters):\n",
        "                          nl_results = rand_poly(\n",
        "                          [\n",
        "                              image[0, j - 1, k - 1].item(),\n",
        "                              image[0, j - 1, k].item(),\n",
        "                              image[0, j - 1, k + 1].item(),\n",
        "                              image[0, j, k - 1].item(),\n",
        "                              image[0, j, k].item(),\n",
        "                              image[0, j, k + 1].item(),\n",
        "                              image[0, j + 1, k - 1].item(),\n",
        "                              image[0, j + 1, k].item(),\n",
        "                              image[0, j + 1, k + 1].item()\n",
        "                          ]\n",
        "                          )\n",
        "                          out[bat,i,j - 1, k - 1] = nl_results\n",
        "        else:\n",
        "          out = torch.zeros((BATCH_SIZE,self.filters,14,14))\n",
        "          out = inputs\n",
        "        # print(out.size())\n",
        "        if use_cuda:\n",
        "          out = out.cuda()\n",
        "        if self.opt==True:\n",
        "          out = self.conv_opt(inputs)\n",
        "        x = self.pool(F.relu(self.conv1(out)))\n",
        "        # print(x.size())\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x,1)\n",
        "        # print(x.size())\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.softmax(self.fc2(x))\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRtM2vqBUnZc",
        "outputId": "952b25bc-0a18-42d9-9e3e-dd3ec804cd47"
      },
      "source": [
        "from torchsummary import summary\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "# model = QuanvNet(qc=True, opt=False)\n",
        "model = NLNet(nl=True, opt=False)\n",
        "if use_cuda:\n",
        "    model.cuda()\n",
        "opt = optim.Adam(model.parameters(),lr=0.01)\n",
        "summary(model,(1,14,14))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 12, 12]              80\n",
            "         MaxPool2d-2              [-1, 8, 6, 6]               0\n",
            "            Conv2d-3              [-1, 8, 4, 4]             584\n",
            "         MaxPool2d-4              [-1, 8, 2, 2]               0\n",
            "            Linear-5                   [-1, 16]             528\n",
            "           Dropout-6                   [-1, 16]               0\n",
            "            Linear-7                   [-1, 10]             170\n",
            "================================================================\n",
            "Total params: 1,362\n",
            "Trainable params: 1,362\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.01\n",
            "Params size (MB): 0.01\n",
            "Estimated Total Size (MB): 0.02\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anJ-e0o1Uqzx",
        "outputId": "2127bc7b-c200-4e80-aed3-6a37c8f316a7"
      },
      "source": [
        "for p in model.parameters():\n",
        "    print(p.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1, 3, 3])\n",
            "torch.Size([1])\n",
            "torch.Size([8, 1, 3, 3])\n",
            "torch.Size([8])\n",
            "torch.Size([8, 8, 3, 3])\n",
            "torch.Size([8])\n",
            "torch.Size([16, 32])\n",
            "torch.Size([16])\n",
            "torch.Size([10, 16])\n",
            "torch.Size([10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "id": "AOYhpACtUsqV",
        "outputId": "e80ed074-22a9-48ed-a862-b19f0ba97fd4"
      },
      "source": [
        "losses = []\n",
        "accs = []\n",
        "for epoch in range(1000):\n",
        "  train_loss = 0\n",
        "  acc = 0\n",
        "  for (x_train, y_train) in train_loader:\n",
        "    # print(y_train)\n",
        "    opt.zero_grad()\n",
        "    outputs = model(x_train.cuda() if use_cuda else x_train)\n",
        "    _, preds = torch.max(outputs,1)\n",
        "    acc += (preds==(y_train.cuda() if use_cuda else y_train)).sum().item()\n",
        "    loss = criterion(outputs,(y_train.cuda() if use_cuda else y_train))\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    train_loss += loss\n",
        "    del loss\n",
        "  acc /= n_train\n",
        "  train_loss /= (n_train/BATCH_SIZE)\n",
        "  if epoch%10 == 9:\n",
        "    if epoch%10 == 9:\n",
        "      print(epoch+1,train_loss)\n",
        "    losses.append(train_loss.item())\n",
        "  if epoch%10 == 9:\n",
        "    accs.append(acc) \n",
        "  del acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10 tensor(2.1761, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "20 tensor(2.0835, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "30 tensor(2.0856, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "40 tensor(2.0513, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "50 tensor(2.0138, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "60 tensor(2.0490, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "70 tensor(2.0314, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "80 tensor(2.0932, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "90 tensor(2.0262, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "100 tensor(2.0202, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "110 tensor(2.0224, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "120 tensor(2.0458, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "130 tensor(2.0396, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "140 tensor(2.0643, device='cuda:0', grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-e93efc7d4f62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# print(y_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-eeeab1aebabd>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     28\u001b[0m                               \u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                               \u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                               \u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                               \u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                               \u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PR9x8nFrUu_v"
      },
      "source": [
        "from matplotlib.pyplot import plot\n",
        "x = np.arange(0,10000,10)\n",
        "plot(x,losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "507ajPGfUxF5"
      },
      "source": [
        "x = np.arange(0,10000,10)\n",
        "plot(x,accs)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}